

# Data Exploration, Preprocessing, and Modeling on Kaggle Datasets
This project performs Exploratory Data Analysis (EDA), data cleaning, feature engineering, clustering, anomaly detection, and modeling on two datasets from Kaggle: one tabular dataset and one time series dataset. The goal is to gain insights through EDA and build predictive models using AutoML.

Project Structure
Data Selection

Tabular Dataset: NYC Taxi Trip Duration - diverse data types for comprehensive EDA.
Time Series Dataset: COVID-19 Cases and Vaccinations - daily time series data for trend and anomaly analysis.
Tasks

Data Preprocessing and Cleaning: Detailed data cleaning steps, such as missing value imputation and encoding categorical variables.
EDA and Visualization: Visualizations to analyze data distributions, correlations, trends, and seasonal patterns.
Clustering and Anomaly Detection: Clustering and anomaly elimination to improve data quality.
Feature Processing and Selection: Feature engineering and selection to enhance model performance.
Model Building with AutoML: Building and evaluating models using AutoViML, including ensemble techniques.
Project Requirements
Install required packages:

bash
Copy code
pip install pandas numpy seaborn matplotlib scikit-learn autoviml pandas-profiling sweetviz
Project Workflow
1. Data Preprocessing and Cleaning
Imputation of Missing Values: For each dataset, missing values are handled using Simple Imputer for numeric data and most-frequent imputation for categorical data.
Encoding Categorical Data: Categorical features are converted to numeric using Label Encoding.
Standardization: Features are standardized for consistent model performance.
2. Exploratory Data Analysis (EDA)
Using Auto EDA and Auto DS tools for quick insights, combined with manual visualizations:

Correlation Matrix: Heatmap to identify correlations among features.
Distribution Analysis: Histograms for feature distributions.
Box Plots: Outlier detection and insight into feature ranges.
Time Series Plots (for COVID-19 data): Visualizing trends, seasonality, and anomalies over time.
3. Clustering and Anomaly Detection
KMeans Clustering: Group data to identify similar patterns.
Anomaly Detection with Isolation Forest: Flag potential anomalies in the dataset for review and possible elimination.
4. Feature Engineering and Selection
PCA: Reduces feature dimensions while retaining 95% variance for easier model training.
Date-Based Feature Engineering (for time series): Extract month, day, and other temporal features.
5. Model Building with AutoML (AutoViML)
Train-Test Split: Prepare data for modeling with an 80-20 split.
AutoML with AutoViML: Automatically builds and tunes models using various algorithms.
Ensemble Models: Built with techniques like bagging and boosting to improve model accuracy.
6. Evaluation and Analysis
Performance Metrics: Evaluate models using accuracy, precision, recall, and F1 score.
Example Code
Hereâ€™s a snippet for setting up AutoViML modeling:

python
Copy code
from autoviml.Auto_ViML import Auto_ViML
model = Auto_ViML()
model.fit(X_train, y_train, X_test=X_test, y_test=y_test, feature_reduction=True, scoring_parameter='accuracy')
Visualizations
Correlation Heatmaps
Time Series Trend Analysis
Cluster Plots and Anomaly Detection
Results and Analysis
All results, including visualizations, preprocessing steps, and model performance, are documented in detail.

Conclusion
This project demonstrates the importance of thorough EDA, data preparation, and feature selection in model building. AutoML proves efficient in selecting optimal models for each dataset type, improving prediction accuracy and reliability.

Acknowledgments
Thanks to Kaggle for the datasets used in this project.

